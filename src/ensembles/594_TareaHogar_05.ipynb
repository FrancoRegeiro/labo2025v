{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "ir",
      "display_name": "R"
    },
    "language_info": {
      "name": "R"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FrancoRegeiro/labo2025v/blob/main/src/ensembles/594_TareaHogar_05.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tarea para el Hogar 05"
      ],
      "metadata": {
        "id": "0cEmzeUKFkPh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esta Tarea para el Hogar 05 se entrega el final de la cuarta clase\n",
        "<br> se espera de usted que intente avanzar con los desafios propuestos y que los traiga terminados para la Clase 05 que será el miercoles 03 de septiembre"
      ],
      "metadata": {
        "id": "nSICPpyTGQmC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  1. Overfitting the Public Leaderboard"
      ],
      "metadata": {
        "id": "DenyKXkiJ5JN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Leer  https://medium.com/hmif-itb/overfitting-the-leaderboard-da25172ac62e\n",
        "( 8 minutos )"
      ],
      "metadata": {
        "id": "l-K2_ZsZGrVD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Hiperparámetros del LightGBM"
      ],
      "metadata": {
        "id": "K9GkTOk5J9t3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Los objetivos de esta tarea son:\n",
        "\n",
        "\n",
        "*   Aumentar la rentabilidad de la campaña de marketing de retención proactiva de clientes.\n",
        "*   Generar un mejor modelo optimizando sus hiperparámetros\n",
        "*   Conceptual : investigar los mas relevantes hiperparámetros de LightGBM\n",
        "*   Familiarizarse con la Bayesian Optimization, sus largos tiempos de corrida y opciones para reducirlos\n",
        "*   Familiarizarse con el uso de máquinas virtuales de Google Colab\n",
        "*   Ver un pipeline completo de optimización de hiperparámetros y puesta en producción"
      ],
      "metadata": {
        "id": "VmEFy0ukKL5T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "LightGBM cuenta con mas de 60 hiperparámetros, siendo posible utilizar 40 al mismo tiempo, aunque no razonable.\n",
        "<br> La documentación oficial de los hiperparámetros de LightGBM es  https://lightgbm.readthedocs.io/en/latest/Parameters.html#core-parameters\n"
      ],
      "metadata": {
        "id": "5yvlS6JQLRMd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se lo alerta sobre que una Optimizacion Bayesiana lleva varias horas de corrida, y usted deberá correr VARIAS optimizaciones para descubrir cuales parámetros conviene optimizar.\n",
        "<br> A pesar que la próxima clase es recien en viernes 01 de agosto, inicie la tarea con tiempo, aprenda a planificar estratégicamente sus corridas como un@ científ@  de datos."
      ],
      "metadata": {
        "id": "eydI4YNAsFaf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Es necesario investigar cuales son los hiperparámetros de LightGBM que vale la pena optimizar en una Bayesian Optimization, ya que los realmente utiles son apenas un reducido subconjunto.\n",
        "<br>Usted deberá investigar cuales son los hiperparámetros mas relevantes de LightGBM, su primer alternativa es preguntándole a su amigo con capacidades especiales ChatGPT o sus endogámicos familiares Claude, DeepSeek, Gemini, Grok, etc\n",
        "<br> La segunda alternativa es la propia documentación de LightGBM  https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html\n"
      ],
      "metadata": {
        "id": "RzU4S0SeMcpp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adicionalmente podra buscar información como la que proveen esta diminuta muestra aleatoria de artículos ligeros:\n",
        "* https://machinelearningmastery.com/light-gradient-boosted-machine-lightgbm-ensemble/\n",
        "*  https://medium.com/@sarahzouinina/a-deep-dive-into-lightgbm-how-to-choose-and-tune-parameters-7c584945842e\n",
        "*  https://www.kaggle.com/code/somang1418/tuning-hyperparameters-under-10-minutes-lgbm\n",
        "*  https://towardsdatascience.com/beginners-guide-to-the-must-know-lightgbm-hyperparameters-a0005a812702/\n",
        "\n",
        "\n",
        "<br>  La muestra anterior se brinda a modo de ejemplo, usted deberá buscar muuuuchas  fuentes adicionales de información\n",
        "<br> Tenga presente que LightGBM es el estado del arte en modelado predictivo para datasets estructurado, que son el 90% del trabajo del 95% de los Data Scientists en Argentina."
      ],
      "metadata": {
        "id": "LNptUgI_NWWG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El desafío de esta tarea es:\n",
        "* Qué hiperparparámetros conviene optimizar?  Las recomendaciones de los artículos ligeros es siempre sensata?  Sus autores realmente hicieron experimentos o son siemplemente escritores de entretenimiento carente de base científica?\n",
        "* Elegidos los hiperparámetros, cual es el  <desde, hasta> que se debe utilizar en la Bayesian Optimization ?\n",
        "* Realmente vale la pena optimizar 10 o 16 hiperparámetros al mismo tiempo ?  No resulta contraproducente una búsqueda en un espacio de tal alta dimensionalidad ?"
      ],
      "metadata": {
        "id": "WpUThBojODyK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.1  Seteo del ambiente en Google Colab"
      ],
      "metadata": {
        "id": "PX0qg_c0yqob"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGY7H9xza7Zr"
      },
      "source": [
        "Esta parte se debe correr con el runtime en Python3\n",
        "<br>Ir al menu, Runtime -> Change Runtime Type -> Runtime type ->  **Python 3**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PupIBNba7Zr"
      },
      "source": [
        "Conectar la virtual machine donde esta corriendo Google Colab con el  Google Drive, para poder tener persistencia de archivos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9LpZCst5a7Zs",
        "outputId": "9c8f6eb1-89de-4d59-d0f3-533593b39175",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/.drive; to attempt to forcibly remount, call drive.mount(\"/content/.drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# primero establecer el Runtime de Python 3\n",
        "from google.colab import drive\n",
        "drive.mount('/content/.drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYC_F-wla7Zs"
      },
      "source": [
        "Para correr la siguiente celda es fundamental en Arranque en Frio haber copiado el archivo kaggle.json al Google Drive, en la carpeta indicada en el instructivo\n",
        "\n",
        "<br>los siguientes comando estan en shell script de Linux\n",
        "*   Crear las carpetas en el Google Drive\n",
        "*   \"instalar\" el archivo kaggle.json desde el Google Drive a la virtual machine para que pueda ser utilizado por la libreria  kaggle de Python\n",
        "*   Bajar el  **dataset_pequeno**  al  Google Drive  y tambien al disco local de la virtual machine que esta corriendo Google Colab\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "XWLelftXa7Zt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd922bac-26cb-4b66-9e49-452528385f4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ln: failed to create symbolic link '/content/buckets/b1/labo1': File exists\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "%%shell\n",
        "\n",
        "mkdir -p \"/content/.drive/My Drive/labo1\"\n",
        "mkdir -p \"/content/buckets\"\n",
        "ln -s \"/content/.drive/My Drive/labo1\" /content/buckets/b1\n",
        "\n",
        "mkdir -p ~/.kaggle\n",
        "cp /content/buckets/b1/kaggle/kaggle.json  ~/.kaggle\n",
        "chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "\n",
        "mkdir -p /content/buckets/b1/exp\n",
        "mkdir -p /content/buckets/b1/datasets\n",
        "mkdir -p /content/datasets\n",
        "\n",
        "\n",
        "\n",
        "archivo_origen=\"https://storage.googleapis.com/open-courses/austral2025-af91/dataset_pequeno.csv\"\n",
        "archivo_destino=\"/content/datasets/dataset_pequeno.csv\"\n",
        "archivo_destino_bucket=\"/content/buckets/b1/datasets/dataset_pequeno.csv\"\n",
        "\n",
        "if ! test -f $archivo_destino_bucket; then\n",
        "  wget  $archivo_origen  -O $archivo_destino_bucket\n",
        "fi\n",
        "\n",
        "\n",
        "if ! test -f $archivo_destino; then\n",
        "  cp  $archivo_destino_bucket  $archivo_destino\n",
        "fi\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2 Optimizacion Hiperparámetros"
      ],
      "metadata": {
        "id": "oSKhZRToy2F7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esta parte se debe correr con el runtime en lenguaje R Ir al menu, Runtime -> Change Runtime Type -> Runtime type -> R"
      ],
      "metadata": {
        "id": "2kwPpHAtSmix"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2.1 Inicio"
      ],
      "metadata": {
        "id": "xp4-Bj3aYI8d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "limpio el ambiente de R"
      ],
      "metadata": {
        "id": "zy8YTZfESxeJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "format(Sys.time(), \"%a %b %d %X %Y\")"
      ],
      "metadata": {
        "id": "gBq__iAdQliq",
        "outputId": "8782fd3d-7313-487f-ec65-0b2ab73f5d87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "'Sun Nov 02 10:05:20 PM 2025'"
            ],
            "text/markdown": "'Sun Nov 02 10:05:20 PM 2025'",
            "text/latex": "'Sun Nov 02 10:05:20 PM 2025'",
            "text/plain": [
              "[1] \"Sun Nov 02 10:05:20 PM 2025\""
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# limpio la memoria\n",
        "rm(list=ls(all.names=TRUE)) # remove all objects\n",
        "gc(full=TRUE, verbose=FALSE) # garbage collection"
      ],
      "metadata": {
        "id": "7rdVrBojS1IV",
        "outputId": "04f5d99e-b384-4091-fc4b-a2a534ff3651",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table class=\"dataframe\">\n",
              "<caption>A matrix: 2 × 6 of type dbl</caption>\n",
              "<thead>\n",
              "\t<tr><th></th><th scope=col>used</th><th scope=col>(Mb)</th><th scope=col>gc trigger</th><th scope=col>(Mb)</th><th scope=col>max used</th><th scope=col>(Mb)</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "\t<tr><th scope=row>Ncells</th><td> 663721</td><td>35.5</td><td>1454477</td><td>77.7</td><td>1454477</td><td>77.7</td></tr>\n",
              "\t<tr><th scope=row>Vcells</th><td>1234431</td><td> 9.5</td><td>8388608</td><td>64.0</td><td>1975128</td><td>15.1</td></tr>\n",
              "</tbody>\n",
              "</table>\n"
            ],
            "text/markdown": "\nA matrix: 2 × 6 of type dbl\n\n| <!--/--> | used | (Mb) | gc trigger | (Mb) | max used | (Mb) |\n|---|---|---|---|---|---|---|\n| Ncells |  663721 | 35.5 | 1454477 | 77.7 | 1454477 | 77.7 |\n| Vcells | 1234431 |  9.5 | 8388608 | 64.0 | 1975128 | 15.1 |\n\n",
            "text/latex": "A matrix: 2 × 6 of type dbl\n\\begin{tabular}{r|llllll}\n  & used & (Mb) & gc trigger & (Mb) & max used & (Mb)\\\\\n\\hline\n\tNcells &  663721 & 35.5 & 1454477 & 77.7 & 1454477 & 77.7\\\\\n\tVcells & 1234431 &  9.5 & 8388608 & 64.0 & 1975128 & 15.1\\\\\n\\end{tabular}\n",
            "text/plain": [
              "       used    (Mb) gc trigger (Mb) max used (Mb)\n",
              "Ncells  663721 35.5 1454477    77.7 1454477  77.7\n",
              "Vcells 1234431  9.5 8388608    64.0 1975128  15.1"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2.2 Carga de Librerias"
      ],
      "metadata": {
        "id": "kuPfQ7ksjwW3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# cargo las librerias que necesito\n",
        "require(\"data.table\")\n",
        "require(\"parallel\")\n",
        "\n",
        "if( !require(\"primes\") ) install.packages(\"primes\")\n",
        "require(\"primes\")\n",
        "\n",
        "if( !require(\"utils\") ) install.packages(\"utils\")\n",
        "require(\"utils\")\n",
        "\n",
        "if( !require(\"rlist\") ) install.packages(\"rlist\")\n",
        "require(\"rlist\")\n",
        "\n",
        "if( !require(\"yaml\")) install.packages(\"yaml\")\n",
        "require(\"yaml\")\n",
        "\n",
        "if( !require(\"lightgbm\") ) install.packages(\"lightgbm\")\n",
        "require(\"lightgbm\")\n",
        "\n",
        "if( !require(\"DiceKriging\") ) install.packages(\"DiceKriging\")\n",
        "require(\"DiceKriging\")\n",
        "\n",
        "if( !require(\"mlrMBO\") ) install.packages(\"mlrMBO\")\n",
        "require(\"mlrMBO\")"
      ],
      "metadata": {
        "id": "lVyxLaJ1j1J_",
        "outputId": "1e902b6b-f62d-42e7-ef3f-8cdace841dec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading required package: data.table\n",
            "\n",
            "Loading required package: parallel\n",
            "\n",
            "Loading required package: primes\n",
            "\n",
            "Loading required package: rlist\n",
            "\n",
            "Loading required package: yaml\n",
            "\n",
            "Loading required package: lightgbm\n",
            "\n",
            "Loading required package: DiceKriging\n",
            "\n",
            "Loading required package: mlrMBO\n",
            "\n",
            "Loading required package: mlr\n",
            "\n",
            "Loading required package: ParamHelpers\n",
            "\n",
            "Loading required package: smoof\n",
            "\n",
            "Loading required package: checkmate\n",
            "\n",
            "\n",
            "Attaching package: ‘checkmate’\n",
            "\n",
            "\n",
            "The following object is masked from ‘package:DiceKriging’:\n",
            "\n",
            "    checkNames\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2.3 Definicion de Parametros"
      ],
      "metadata": {
        "id": "Iz-6Qt6BUaA3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "aqui debe cargar SU semilla primigenia\n",
        "<br>recuerde cambiar el numero de experimento en cada corrida nueva"
      ],
      "metadata": {
        "id": "cOdlKd7lUm2I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PARAM <- list()\n",
        "PARAM$experimento <- 5940\n",
        "PARAM$semilla_primigenia <- 100019\n"
      ],
      "metadata": {
        "id": "ASYkebOu2mF6"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PARAM$kaggle$competencia <- \"labo-i-2025-virtual-analista-sr\"\n",
        "PARAM$kaggle$cortes <- seq(10000, 12000, by= 500)"
      ],
      "metadata": {
        "id": "ezOhQdbA293o"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# un undersampling de 0.1  toma solo el 10% de los CONTINUA\n",
        "# undersampling de 1.0  implica tomar TODOS los datos\n",
        "\n",
        "PARAM$trainingstrategy$undersampling <- 0.5"
      ],
      "metadata": {
        "id": "jtB0Lub42rHO"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parametros LightGBM\n",
        "\n",
        "PARAM$hyperparametertuning$xval_folds <- 5\n",
        "\n",
        "# parametros fijos del LightGBM (se pisan con los de la BO)\n",
        "PARAM$lgbm$param_fijos <- list(\n",
        "  boosting            = \"gbdt\",\n",
        "  objective           = \"binary\",\n",
        "  metric              = \"auc\",\n",
        "  first_metric_only   = TRUE,\n",
        "  boost_from_average  = TRUE,\n",
        "  feature_pre_filter  = FALSE,\n",
        "  force_row_wise      = TRUE,\n",
        "  verbosity           = -100,\n",
        "  seed                = PARAM$semilla_primigenia,\n",
        "\n",
        "  # regularizaciones “base”\n",
        "  lambda_l1           = 0.0,\n",
        "  lambda_l2           = 0.0,\n",
        "  min_gain_to_split   = 0.0,\n",
        "  min_sum_hessian_in_leaf = 1e-3,\n",
        "\n",
        "  # histogramas\n",
        "  max_bin             = 31L,\n",
        "\n",
        "  # bagging on por defecto (BO ajusta fracciones)\n",
        "  bagging_freq        = 1L,\n",
        "  is_unbalance        = FALSE,\n",
        "  scale_pos_weight    = 1.0,\n",
        "\n",
        "  # límites de iteraciones y LR de arranque (BO los ajusta)\n",
        "  num_iterations      = 1200,\n",
        "  learning_rate       = 0.05,\n",
        "\n",
        "  # fracciones/estructura de arranque (BO ajusta)\n",
        "  feature_fraction    = 0.7,\n",
        "  num_leaves          = 255,\n",
        "  min_data_in_leaf    = 3000,\n",
        "\n",
        "  # max_depth fijo en -1; dejamos que num_leaves controle complejidad\n",
        "  max_depth           = -1L\n",
        ")"
      ],
      "metadata": {
        "id": "OFxm-xiNUOJX"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aqui se definen los hiperparámetros de LightGBM que participan de la Bayesian Optimization\n",
        "<br> si es un numero entero debe ir  makeIntegerParam\n",
        "<br> si es un numero real (con decimales) debe ir  makeNumericParam\n",
        "<br> es muy importante leer cuales son un lower y upper  permitidos y ademas razonables"
      ],
      "metadata": {
        "id": "D5Yj-JV4yvOt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Aqui se cargan los bordes de los hiperparametros de la BO\n",
        "PARAM$hypeparametertuning$hs <- makeParamSet(\n",
        "  makeNumericParam(\"learning_rate\",    lower = 0.01, upper = 0.15),\n",
        "  makeIntegerParam(\"num_iterations\",   lower = 400L, upper = 2000L),\n",
        "  makeNumericParam(\"feature_fraction\", lower = 0.5,  upper = 0.9),\n",
        "  makeNumericParam(\"bagging_fraction\", lower = 0.6,  upper = 1.0),\n",
        "  makeIntegerParam(\"num_leaves\",       lower = 63L,  upper = 1023L),\n",
        "  makeIntegerParam(\"min_data_in_leaf\", lower = 200L, upper = 8000L),\n",
        "  makeNumericParam(\"lambda_l1\", lower = 0.0, upper = 1.0),\n",
        "  makeNumericParam(\"lambda_l2\", lower = 0.0, upper = 1.0)\n",
        ")"
      ],
      "metadata": {
        "id": "jENpR26ZyuS8"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A mayor cantidad de hiperparámetros, se debe aumentar las iteraciones de la Bayesian Optimization\n",
        "<br> 30 es un valor muy tacaño, pero corre rápido\n",
        "<br> deberia partir de 50, alcanzando los 100 si se dispone de tiempo"
      ],
      "metadata": {
        "id": "-_RPFUb3zMoW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PARAM$hyperparametertuning$iteraciones <- 100 # iteraciones bayesianas"
      ],
      "metadata": {
        "id": "q5Rd3pnbzSiG"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2.4  Preprocesamiento"
      ],
      "metadata": {
        "id": "4RWZXL1VZjMI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# carpeta de trabajo\n",
        "\n",
        "setwd(\"/content/buckets/b1/exp\")\n",
        "experimento_folder <- paste0(\"HT\", PARAM$experimento)\n",
        "dir.create(experimento_folder, showWarnings=FALSE)\n",
        "setwd( paste0(\"/content/buckets/b1/exp/\", experimento_folder ))"
      ],
      "metadata": {
        "id": "j3toG9-lZm4K"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lectura del dataset\n",
        "\n",
        "dataset <- fread(\"/content/datasets/dataset_pequeno.csv\")"
      ],
      "metadata": {
        "id": "FM3lxKoLZ643"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_train <- dataset[foto_mes %in% c(202107)]"
      ],
      "metadata": {
        "id": "OsJ-91UeZ-I_"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# paso la clase a binaria que tome valores {0,1}  enteros\n",
        "#  BAJA+1 y BAJA+2  son  1,   CONTINUA es 0\n",
        "\n",
        "dataset_train[,\n",
        "  clase01 := ifelse(clase_ternaria %in% c(\"BAJA+2\",\"BAJA+1\"), 1L, 0L)\n",
        "]"
      ],
      "metadata": {
        "id": "vrWE7BE0aB2J"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# defino los datos que forma parte del training\n",
        "# aqui se hace el undersampling de los CONTINUA\n",
        "# notar que para esto utilizo la SEGUNDA semilla\n",
        "\n",
        "set.seed(PARAM$semilla_primigenia, kind = \"L'Ecuyer-CMRG\")\n",
        "dataset_train[, azar := runif(nrow(dataset_train))]\n",
        "dataset_train[, training := 0L]\n",
        "\n",
        "dataset_train[\n",
        "  foto_mes %in% c(202107) &\n",
        "    (azar <= PARAM$trainingstrategy$undersampling | clase_ternaria %in% c(\"BAJA+1\", \"BAJA+2\")),\n",
        "  training := 1L\n",
        "]"
      ],
      "metadata": {
        "id": "jP7YlQBnaW6W"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# los campos que se van a utilizar\n",
        "\n",
        "campos_buenos <- setdiff(\n",
        "  colnames(dataset_train),\n",
        "  c(\"clase_ternaria\", \"clase01\", \"azar\", \"training\")\n",
        ")"
      ],
      "metadata": {
        "id": "xElu4s5W4rX7"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dejo los datos en el formato que necesita LightGBM\n",
        "\n",
        "dtrain <- lgb.Dataset(\n",
        "  data= data.matrix(dataset_train[training == 1L, campos_buenos, with= FALSE]),\n",
        "  label= dataset_train[training == 1L, clase01],\n",
        "  free_raw_data= FALSE\n",
        ")\n",
        "\n",
        "nrow(dtrain)\n",
        "ncol(dtrain)"
      ],
      "metadata": {
        "id": "PppMHcGYaaol",
        "outputId": "dc9c5425-7e47-4b4f-f7cc-f43feaa6456b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "83617"
            ],
            "text/markdown": "83617",
            "text/latex": "83617",
            "text/plain": [
              "[1] 83617"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "154"
            ],
            "text/markdown": "154",
            "text/latex": "154",
            "text/plain": [
              "[1] 154"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.2.5 Configuracion Bayesian Optimization"
      ],
      "metadata": {
        "id": "Ta-EkOu3cphF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# En el argumento x llegan los parmaetros de la bayesiana\n",
        "#  devuelve la AUC en cross validation del modelo entrenado\n",
        "\n",
        "EstimarGanancia_AUC_lightgbm <- function(x) {\n",
        "\n",
        "  # x pisa (o agrega) a param_fijos\n",
        "  param_completo <- modifyList(PARAM$lgbm$param_fijos, x)\n",
        "\n",
        "  modelocv <- lgb.cv(\n",
        "  data        = dtrain,\n",
        "  nfold       = PARAM$hyperparametertuning$xval_folds,  # 5 folds ok (si querés speed: 3)\n",
        "  stratified  = TRUE,\n",
        "  param       = param_completo,\n",
        "  early_stopping_rounds = 100,\n",
        "  record      = TRUE\n",
        ")\n",
        "\n",
        "  # obtengo la ganancia\n",
        "  AUC <- modelocv$best_score\n",
        "\n",
        "  # hago espacio en la memoria\n",
        "  rm(modelocv)\n",
        "  gc(full= TRUE, verbose= FALSE)\n",
        "\n",
        "  message(format(Sys.time(), \"%a %b %d %X %Y\"), \" AUC \", AUC)\n",
        "\n",
        "  return(AUC)\n",
        "}"
      ],
      "metadata": {
        "id": "cjgfurjdfiXb"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aqui comienza la configuracion de la Bayesian Optimization\n",
        "\n",
        "# en este archivo quedan la evolucion binaria de la BO\n",
        "kbayesiana <- \"bayesiana.RDATA\"\n",
        "\n",
        "funcion_optimizar <- EstimarGanancia_AUC_lightgbm # la funcion que voy a maximizar\n",
        "\n",
        "configureMlr(show.learner.output= FALSE)\n",
        "\n",
        "# configuro la busqueda bayesiana,  los hiperparametros que se van a optimizar\n",
        "# por favor, no desesperarse por lo complejo\n",
        "\n",
        "obj.fun <- makeSingleObjectiveFunction(\n",
        "  fn= funcion_optimizar, # la funcion que voy a maximizar\n",
        "  minimize= FALSE, # estoy Maximizando la ganancia\n",
        "  noisy= TRUE,\n",
        "  par.set= PARAM$hypeparametertuning$hs, # definido al comienzo del programa\n",
        "  has.simple.signature= FALSE # paso los parametros en una lista\n",
        ")\n",
        "\n",
        "# cada 600 segundos guardo el resultado intermedio\n",
        "ctrl <- makeMBOControl(\n",
        "  save.on.disk.at.time= 600, # se graba cada 600 segundos\n",
        "  save.file.path= kbayesiana\n",
        ") # se graba cada 600 segundos\n",
        "\n",
        "# indico la cantidad de iteraciones que va a tener la Bayesian Optimization\n",
        "ctrl <- setMBOControlTermination(\n",
        "  ctrl,\n",
        "  iters= PARAM$hyperparametertuning$iteraciones\n",
        ") # cantidad de iteraciones\n",
        "\n",
        "# defino el método estandar para la creacion de los puntos iniciales,\n",
        "# los \"No Inteligentes\"\n",
        "ctrl <- setMBOControlInfill(ctrl, crit= makeMBOInfillCritEI())\n",
        "\n",
        "# establezco la funcion que busca el maximo\n",
        "surr.km <- makeLearner(\n",
        "  \"regr.km\",\n",
        "  predict.type= \"se\",\n",
        "  covtype= \"matern3_2\",\n",
        "  control= list(trace= TRUE)\n",
        ")\n"
      ],
      "metadata": {
        "id": "WLi_o1hocvN-"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.2.6 Corrida Bayesian Optimization"
      ],
      "metadata": {
        "id": "_uUeVo5pc4zc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# inicio la optimizacion bayesiana, retomando si ya existe\n",
        "# es la celda mas lenta de todo el notebook\n",
        "\n",
        "if (!file.exists(kbayesiana)) {\n",
        "  bayesiana_salida <- mbo(obj.fun, learner= surr.km, control= ctrl)\n",
        "} else {\n",
        "  bayesiana_salida <- mboContinue(kbayesiana) # retomo en caso que ya exista\n",
        "}"
      ],
      "metadata": {
        "id": "RcABNaKGciaz",
        "outputId": "ff1b8b36-cf4a-43fa-f2a3-89648c3ea213",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Computing y column(s) for design. Not provided.\n",
            "\n",
            "Sun Nov 02 10:06:37 PM 2025 AUC 0.92362893838148\n",
            "\n",
            "Sun Nov 02 10:07:22 PM 2025 AUC 0.926014775334865\n",
            "\n",
            "Sun Nov 02 10:08:28 PM 2025 AUC 0.926642797615566\n",
            "\n",
            "Sun Nov 02 10:08:57 PM 2025 AUC 0.925717483674617\n",
            "\n",
            "Sun Nov 02 10:12:08 PM 2025 AUC 0.926258846342306\n",
            "\n",
            "Sun Nov 02 10:12:52 PM 2025 AUC 0.925646298691856\n",
            "\n",
            "Sun Nov 02 10:13:40 PM 2025 AUC 0.924151588613986\n",
            "\n",
            "Sun Nov 02 10:14:23 PM 2025 AUC 0.928812125539381\n",
            "\n",
            "Sun Nov 02 10:15:36 PM 2025 AUC 0.925019737274188\n",
            "\n",
            "Sun Nov 02 10:16:16 PM 2025 AUC 0.925485608242785\n",
            "\n",
            "Sun Nov 02 10:16:40 PM 2025 AUC 0.926375420479938\n",
            "\n",
            "Sun Nov 02 10:17:53 PM 2025 AUC 0.926000620171663\n",
            "\n",
            "Sun Nov 02 10:19:30 PM 2025 AUC 0.924579729119614\n",
            "\n",
            "Sun Nov 02 10:20:30 PM 2025 AUC 0.929715939784367\n",
            "\n",
            "Sun Nov 02 10:21:59 PM 2025 AUC 0.920769130261765\n",
            "\n",
            "Sun Nov 02 10:22:26 PM 2025 AUC 0.926468510354147\n",
            "\n",
            "Sun Nov 02 10:23:30 PM 2025 AUC 0.923718368356474\n",
            "\n",
            "Sun Nov 02 10:23:53 PM 2025 AUC 0.927584806011534\n",
            "\n",
            "Sun Nov 02 10:24:28 PM 2025 AUC 0.92634060606812\n",
            "\n",
            "Sun Nov 02 10:25:08 PM 2025 AUC 0.926489965315333\n",
            "\n",
            "Sun Nov 02 10:25:54 PM 2025 AUC 0.926063739603787\n",
            "\n",
            "Sun Nov 02 10:26:59 PM 2025 AUC 0.92812250984611\n",
            "\n",
            "Sun Nov 02 10:30:25 PM 2025 AUC 0.926201477786924\n",
            "\n",
            "Sun Nov 02 10:31:11 PM 2025 AUC 0.924587051019696\n",
            "\n",
            "Sun Nov 02 10:31:55 PM 2025 AUC 0.925824014246173\n",
            "\n",
            "Sun Nov 02 10:33:01 PM 2025 AUC 0.927965611985815\n",
            "\n",
            "Sun Nov 02 10:33:23 PM 2025 AUC 0.921355791913381\n",
            "\n",
            "Sun Nov 02 10:34:10 PM 2025 AUC 0.924255950666496\n",
            "\n",
            "Sun Nov 02 10:35:25 PM 2025 AUC 0.924708997222526\n",
            "\n",
            "Sun Nov 02 10:35:49 PM 2025 AUC 0.926293200292733\n",
            "\n",
            "Sun Nov 02 10:41:42 PM 2025 AUC 0.927434271155806\n",
            "\n",
            "Sun Nov 02 10:42:23 PM 2025 AUC 0.925825359457338\n",
            "\n",
            "[mbo] 0: learning_rate=0.0914; num_iterations=786; feature_fraction=0.747; bagging_fraction=0.789; num_leaves=458; min_data_in_leaf=6660; lambda_l1=0.403; lambda_l2=0.544 : y = 0.924 : 53.7 secs : initdesign\n",
            "\n",
            "[mbo] 0: learning_rate=0.0965; num_iterations=803; feature_fraction=0.699; bagging_fraction=0.908; num_leaves=666; min_data_in_leaf=5768; lambda_l1=0.762; lambda_l2=0.487 : y = 0.926 : 45.1 secs : initdesign\n",
            "\n",
            "[mbo] 0: learning_rate=0.0502; num_iterations=1526; feature_fraction=0.707; bagging_fraction=0.812; num_leaves=286; min_data_in_leaf=4044; lambda_l1=0.424; lambda_l2=0.284 : y = 0.927 : 65.9 secs : initdesign\n",
            "\n",
            "[mbo] 0: learning_rate=0.0654; num_iterations=913; feature_fraction=0.713; bagging_fraction=0.647; num_leaves=450; min_data_in_leaf=1911; lambda_l1=0.848; lambda_l2=0.88 : y = 0.926 : 29.3 secs : initdesign\n",
            "\n",
            "[mbo] 0: learning_rate=0.0415; num_iterations=1184; feature_fraction=0.553; bagging_fraction=0.946; num_leaves=782; min_data_in_leaf=5080; lambda_l1=0.72; lambda_l2=0.633 : y = 0.926 : 191.2 secs : initdesign\n",
            "\n",
            "[mbo] 0: learning_rate=0.109; num_iterations=1010; feature_fraction=0.834; bagging_fraction=0.918; num_leaves=708; min_data_in_leaf=6098; lambda_l1=0.618; lambda_l2=0.24 : y = 0.926 : 43.5 secs : initdesign\n",
            "\n",
            "[mbo] 0: learning_rate=0.0887; num_iterations=871; feature_fraction=0.776; bagging_fraction=0.748; num_leaves=568; min_data_in_leaf=6880; lambda_l1=0.475; lambda_l2=0.698 : y = 0.924 : 47.8 secs : initdesign\n",
            "\n",
            "[mbo] 0: learning_rate=0.0492; num_iterations=709; feature_fraction=0.8; bagging_fraction=0.825; num_leaves=528; min_data_in_leaf=1722; lambda_l1=0.576; lambda_l2=0.388 : y = 0.929 : 43.7 secs : initdesign\n",
            "\n",
            "[mbo] 0: learning_rate=0.0816; num_iterations=1271; feature_fraction=0.603; bagging_fraction=0.843; num_leaves=94; min_data_in_leaf=5837; lambda_l1=0.829; lambda_l2=0.786 : y = 0.925 : 72.8 secs : initdesign\n",
            "\n",
            "[mbo] 0: learning_rate=0.0772; num_iterations=1848; feature_fraction=0.8; bagging_fraction=0.706; num_leaves=484; min_data_in_leaf=4217; lambda_l1=0.249; lambda_l2=0.147 : y = 0.925 : 39.5 secs : initdesign\n",
            "\n",
            "[mbo] 0: learning_rate=0.123; num_iterations=961; feature_fraction=0.765; bagging_fraction=0.679; num_leaves=940; min_data_in_leaf=864; lambda_l1=0.467; lambda_l2=0.53 : y = 0.926 : 24.0 secs : initdesign\n",
            "\n",
            "[mbo] 0: learning_rate=0.0567; num_iterations=1306; feature_fraction=0.858; bagging_fraction=0.927; num_leaves=386; min_data_in_leaf=5378; lambda_l1=0.671; lambda_l2=0.675 : y = 0.926 : 73.3 secs : initdesign\n",
            "\n",
            "[mbo] 0: learning_rate=0.0221; num_iterations=1909; feature_fraction=0.762; bagging_fraction=0.783; num_leaves=812; min_data_in_leaf=4727; lambda_l1=0.254; lambda_l2=0.774 : y = 0.925 : 96.7 secs : initdesign\n",
            "\n",
            "[mbo] 0: learning_rate=0.0393; num_iterations=1757; feature_fraction=0.616; bagging_fraction=0.726; num_leaves=241; min_data_in_leaf=415; lambda_l1=0.629; lambda_l2=0.119 : y = 0.93 : 60.7 secs : initdesign\n",
            "\n",
            "[mbo] 0: learning_rate=0.125; num_iterations=466; feature_fraction=0.521; bagging_fraction=0.611; num_leaves=749; min_data_in_leaf=7423; lambda_l1=0.698; lambda_l2=0.407 : y = 0.921 : 88.5 secs : initdesign\n",
            "\n",
            "[mbo] 0: learning_rate=0.119; num_iterations=1878; feature_fraction=0.653; bagging_fraction=0.88; num_leaves=254; min_data_in_leaf=1462; lambda_l1=0.195; lambda_l2=0.331 : y = 0.926 : 27.0 secs : initdesign\n",
            "\n",
            "[mbo] 0: learning_rate=0.0617; num_iterations=1680; feature_fraction=0.641; bagging_fraction=0.818; num_leaves=888; min_data_in_leaf=7843; lambda_l1=0.341; lambda_l2=0.197 : y = 0.924 : 64.6 secs : initdesign\n",
            "\n",
            "[mbo] 0: learning_rate=0.114; num_iterations=634; feature_fraction=0.865; bagging_fraction=0.668; num_leaves=151; min_data_in_leaf=2974; lambda_l1=0.092; lambda_l2=0.973 : y = 0.928 : 22.6 secs : initdesign\n",
            "\n",
            "[mbo] 0: learning_rate=0.0709; num_iterations=687; feature_fraction=0.734; bagging_fraction=0.697; num_leaves=347; min_data_in_leaf=3285; lambda_l1=0.0598; lambda_l2=0.182 : y = 0.926 : 35.3 secs : initdesign\n",
            "\n",
            "[mbo] 0: learning_rate=0.104; num_iterations=413; feature_fraction=0.591; bagging_fraction=0.763; num_leaves=855; min_data_in_leaf=578; lambda_l1=0.974; lambda_l2=0.924 : y = 0.926 : 40.2 secs : initdesign\n",
            "\n",
            "[mbo] 0: learning_rate=0.142; num_iterations=1604; feature_fraction=0.573; bagging_fraction=0.889; num_leaves=610; min_data_in_leaf=4845; lambda_l1=0.943; lambda_l2=0.463 : y = 0.926 : 45.7 secs : initdesign\n",
            "\n",
            "[mbo] 0: learning_rate=0.0327; num_iterations=549; feature_fraction=0.627; bagging_fraction=0.985; num_leaves=909; min_data_in_leaf=1142; lambda_l1=0.151; lambda_l2=0.0263 : y = 0.928 : 64.9 secs : initdesign\n",
            "\n",
            "[mbo] 0: learning_rate=0.0184; num_iterations=1435; feature_fraction=0.529; bagging_fraction=0.756; num_leaves=415; min_data_in_leaf=2356; lambda_l1=0.372; lambda_l2=0.864 : y = 0.926 : 205.8 secs : initdesign\n",
            "\n",
            "[mbo] 0: learning_rate=0.131; num_iterations=1248; feature_fraction=0.577; bagging_fraction=0.626; num_leaves=63; min_data_in_leaf=3844; lambda_l1=0.903; lambda_l2=0.258 : y = 0.925 : 45.6 secs : initdesign\n",
            "\n",
            "[mbo] 0: learning_rate=0.101; num_iterations=566; feature_fraction=0.682; bagging_fraction=0.971; num_leaves=161; min_data_in_leaf=6367; lambda_l1=0.54; lambda_l2=0.374 : y = 0.926 : 44.1 secs : initdesign\n",
            "\n",
            "[mbo] 0: learning_rate=0.0263; num_iterations=1379; feature_fraction=0.892; bagging_fraction=0.854; num_leaves=193; min_data_in_leaf=1370; lambda_l1=0.0249; lambda_l2=0.617 : y = 0.928 : 66.2 secs : initdesign\n",
            "\n",
            "[mbo] 0: learning_rate=0.139; num_iterations=1715; feature_fraction=0.82; bagging_fraction=0.653; num_leaves=1012; min_data_in_leaf=7623; lambda_l1=0.111; lambda_l2=0.742 : y = 0.921 : 21.9 secs : initdesign\n",
            "\n",
            "[mbo] 0: learning_rate=0.073; num_iterations=1482; feature_fraction=0.663; bagging_fraction=0.955; num_leaves=978; min_data_in_leaf=7173; lambda_l1=0.304; lambda_l2=0.968 : y = 0.924 : 46.8 secs : initdesign\n",
            "\n",
            "[mbo] 0: learning_rate=0.0289; num_iterations=1054; feature_fraction=0.846; bagging_fraction=0.618; num_leaves=593; min_data_in_leaf=4477; lambda_l1=0.782; lambda_l2=0.583 : y = 0.925 : 76.0 secs : initdesign\n",
            "\n",
            "[mbo] 0: learning_rate=0.136; num_iterations=1553; feature_fraction=0.884; bagging_fraction=0.992; num_leaves=822; min_data_in_leaf=2436; lambda_l1=0.529; lambda_l2=0.0799 : y = 0.926 : 23.7 secs : initdesign\n",
            "\n",
            "[mbo] 0: learning_rate=0.012; num_iterations=1974; feature_fraction=0.507; bagging_fraction=0.864; num_leaves=643; min_data_in_leaf=3534; lambda_l1=0.917; lambda_l2=0.0532 : y = 0.927 : 352.3 secs : initdesign\n",
            "\n",
            "[mbo] 0: learning_rate=0.15; num_iterations=1142; feature_fraction=0.547; bagging_fraction=0.724; num_leaves=304; min_data_in_leaf=2870; lambda_l1=0.163; lambda_l2=0.835 : y = 0.926 : 41.5 secs : initdesign\n",
            "\n",
            "Saved the current state after iteration 1 in the file bayesiana.RDATA.\n",
            "\n",
            "Sun Nov 02 10:43:52 PM 2025 AUC 0.929887286722983\n",
            "\n",
            "[mbo] 1: learning_rate=0.0216; num_iterations=1123; feature_fraction=0.83; bagging_fraction=0.772; num_leaves=270; min_data_in_leaf=202; lambda_l1=0.721; lambda_l2=0.0597 : y = 0.93 : 88.1 secs : infill_ei\n",
            "\n",
            "Sun Nov 02 10:44:53 PM 2025 AUC 0.92814513153908\n",
            "\n",
            "[mbo] 2: learning_rate=0.0378; num_iterations=1232; feature_fraction=0.876; bagging_fraction=0.74; num_leaves=101; min_data_in_leaf=200; lambda_l1=0.551; lambda_l2=0.241 : y = 0.928 : 60.6 secs : infill_ei\n",
            "\n",
            "Sun Nov 02 10:45:50 PM 2025 AUC 0.928639125731967\n",
            "\n",
            "[mbo] 3: learning_rate=0.0368; num_iterations=1075; feature_fraction=0.687; bagging_fraction=0.849; num_leaves=548; min_data_in_leaf=216; lambda_l1=0.735; lambda_l2=0.0141 : y = 0.929 : 56.1 secs : infill_ei\n",
            "\n",
            "Sun Nov 02 10:48:22 PM 2025 AUC 0.930458423763117\n",
            "\n",
            "[mbo] 4: learning_rate=0.0105; num_iterations=1532; feature_fraction=0.678; bagging_fraction=0.754; num_leaves=264; min_data_in_leaf=679; lambda_l1=0.764; lambda_l2=0.0365 : y = 0.93 : 150.9 secs : infill_ei\n",
            "\n",
            "Sun Nov 02 10:50:51 PM 2025 AUC 0.929298361145185\n",
            "\n",
            "[mbo] 5: learning_rate=0.0102; num_iterations=1772; feature_fraction=0.689; bagging_fraction=0.751; num_leaves=212; min_data_in_leaf=203; lambda_l1=0.944; lambda_l2=0.00113 : y = 0.929 : 149.0 secs : infill_ei\n",
            "\n",
            "Sun Nov 02 10:54:14 PM 2025 AUC 0.929254252413941\n",
            "\n",
            "[mbo] 6: learning_rate=0.0101; num_iterations=1415; feature_fraction=0.536; bagging_fraction=0.754; num_leaves=243; min_data_in_leaf=335; lambda_l1=0.623; lambda_l2=0.0498 : y = 0.929 : 201.8 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 7 in the file bayesiana.RDATA.\n",
            "\n",
            "Sun Nov 02 10:56:24 PM 2025 AUC 0.92776443657488\n",
            "\n",
            "[mbo] 7: learning_rate=0.0102; num_iterations=1570; feature_fraction=0.801; bagging_fraction=0.758; num_leaves=387; min_data_in_leaf=1126; lambda_l1=0.711; lambda_l2=0.0781 : y = 0.928 : 129.3 secs : infill_ei\n",
            "\n",
            "Sun Nov 02 10:57:23 PM 2025 AUC 0.929917731372022\n",
            "\n",
            "[mbo] 8: learning_rate=0.0372; num_iterations=979; feature_fraction=0.676; bagging_fraction=0.768; num_leaves=103; min_data_in_leaf=604; lambda_l1=0.807; lambda_l2=0.156 : y = 0.93 : 59.1 secs : infill_ei\n",
            "\n",
            "Sun Nov 02 10:58:50 PM 2025 AUC 0.929969771101657\n",
            "\n",
            "[mbo] 9: learning_rate=0.02; num_iterations=1248; feature_fraction=0.695; bagging_fraction=0.765; num_leaves=365; min_data_in_leaf=562; lambda_l1=0.736; lambda_l2=0.00378 : y = 0.93 : 86.5 secs : infill_ei\n",
            "\n",
            "Sun Nov 02 11:00:01 PM 2025 AUC 0.930400083655472\n",
            "\n",
            "[mbo] 10: learning_rate=0.0253; num_iterations=874; feature_fraction=0.708; bagging_fraction=0.8; num_leaves=255; min_data_in_leaf=615; lambda_l1=0.736; lambda_l2=0.382 : y = 0.93 : 69.8 secs : infill_ei\n",
            "\n",
            "Sun Nov 02 11:01:08 PM 2025 AUC 0.928897789977644\n",
            "\n",
            "[mbo] 11: learning_rate=0.031; num_iterations=736; feature_fraction=0.691; bagging_fraction=0.779; num_leaves=250; min_data_in_leaf=234; lambda_l1=0.709; lambda_l2=0.00359 : y = 0.929 : 66.2 secs : infill_ei\n",
            "\n",
            "Sun Nov 02 11:03:34 PM 2025 AUC 0.929255182507817\n",
            "\n",
            "[mbo] 12: learning_rate=0.0109; num_iterations=832; feature_fraction=0.822; bagging_fraction=0.819; num_leaves=226; min_data_in_leaf=410; lambda_l1=0.768; lambda_l2=0.539 : y = 0.929 : 145.1 secs : infill_ei\n",
            "\n",
            "Sun Nov 02 11:05:34 PM 2025 AUC 0.930364018968979\n",
            "\n",
            "[mbo] 13: learning_rate=0.0127; num_iterations=1507; feature_fraction=0.65; bagging_fraction=0.823; num_leaves=208; min_data_in_leaf=679; lambda_l1=0.206; lambda_l2=0.302 : y = 0.93 : 119.5 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 14 in the file bayesiana.RDATA.\n",
            "\n",
            "Sun Nov 02 11:06:34 PM 2025 AUC 0.929572600047181\n",
            "\n",
            "[mbo] 14: learning_rate=0.0295; num_iterations=1320; feature_fraction=0.834; bagging_fraction=0.807; num_leaves=251; min_data_in_leaf=634; lambda_l1=0.671; lambda_l2=0.0918 : y = 0.93 : 58.6 secs : infill_ei\n",
            "\n",
            "Sun Nov 02 11:08:06 PM 2025 AUC 0.930070091230934\n",
            "\n",
            "[mbo] 15: learning_rate=0.0166; num_iterations=1096; feature_fraction=0.721; bagging_fraction=0.808; num_leaves=234; min_data_in_leaf=606; lambda_l1=0.286; lambda_l2=0.292 : y = 0.93 : 91.0 secs : infill_ei\n",
            "\n",
            "Sun Nov 02 11:10:57 PM 2025 AUC 0.930493515206322\n",
            "\n",
            "[mbo] 16: learning_rate=0.0101; num_iterations=1147; feature_fraction=0.643; bagging_fraction=0.807; num_leaves=271; min_data_in_leaf=710; lambda_l1=0.788; lambda_l2=0.337 : y = 0.93 : 170.8 secs : infill_ei\n",
            "\n",
            "Sun Nov 02 11:12:31 PM 2025 AUC 0.930061122146913\n",
            "\n",
            "[mbo] 17: learning_rate=0.0223; num_iterations=1644; feature_fraction=0.589; bagging_fraction=0.769; num_leaves=652; min_data_in_leaf=681; lambda_l1=0.61; lambda_l2=0.327 : y = 0.93 : 93.0 secs : infill_ei\n",
            "\n",
            "Sun Nov 02 11:13:53 PM 2025 AUC 0.929765227843981\n",
            "\n",
            "[mbo] 18: learning_rate=0.0227; num_iterations=1215; feature_fraction=0.675; bagging_fraction=0.887; num_leaves=356; min_data_in_leaf=695; lambda_l1=0.606; lambda_l2=0.384 : y = 0.93 : 80.7 secs : infill_ei\n",
            "\n",
            "Sun Nov 02 11:15:36 PM 2025 AUC 0.929708028107782\n",
            "\n",
            "[mbo] 19: learning_rate=0.0165; num_iterations=1235; feature_fraction=0.654; bagging_fraction=0.756; num_leaves=268; min_data_in_leaf=803; lambda_l1=0.361; lambda_l2=0.216 : y = 0.93 : 102.2 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 20 in the file bayesiana.RDATA.\n",
            "\n",
            "Sun Nov 02 11:16:51 PM 2025 AUC 0.930126519520619\n",
            "\n",
            "[mbo] 20: learning_rate=0.0177; num_iterations=1694; feature_fraction=0.66; bagging_fraction=0.78; num_leaves=160; min_data_in_leaf=597; lambda_l1=0.737; lambda_l2=0.253 : y = 0.93 : 75.1 secs : infill_ei\n",
            "\n",
            "Sun Nov 02 11:19:21 PM 2025 AUC 0.93020184711631\n",
            "\n",
            "[mbo] 21: learning_rate=0.0122; num_iterations=1507; feature_fraction=0.633; bagging_fraction=0.792; num_leaves=255; min_data_in_leaf=646; lambda_l1=0.724; lambda_l2=0.124 : y = 0.93 : 148.6 secs : infill_ei\n",
            "\n",
            "Sun Nov 02 11:19:56 PM 2025 AUC 0.925283748845828\n",
            "\n",
            "[mbo] 22: learning_rate=0.13; num_iterations=928; feature_fraction=0.848; bagging_fraction=0.811; num_leaves=136; min_data_in_leaf=300; lambda_l1=0.802; lambda_l2=0.0709 : y = 0.925 : 34.2 secs : infill_ei\n",
            "\n",
            "Sun Nov 02 11:22:41 PM 2025 AUC 0.930209676213389\n",
            "\n",
            "[mbo] 23: learning_rate=0.0112; num_iterations=1343; feature_fraction=0.617; bagging_fraction=0.769; num_leaves=119; min_data_in_leaf=670; lambda_l1=0.44; lambda_l2=0.395 : y = 0.93 : 164.2 secs : infill_ei\n",
            "\n",
            "Sun Nov 02 11:24:56 PM 2025 AUC 0.929520285863909\n",
            "\n",
            "[mbo] 24: learning_rate=0.0113; num_iterations=1342; feature_fraction=0.698; bagging_fraction=0.755; num_leaves=219; min_data_in_leaf=605; lambda_l1=0.745; lambda_l2=0.398 : y = 0.93 : 133.6 secs : infill_ei\n",
            "\n",
            "Sun Nov 02 11:26:15 PM 2025 AUC 0.930434902875613\n",
            "\n",
            "[mbo] 25: learning_rate=0.0214; num_iterations=1036; feature_fraction=0.648; bagging_fraction=0.83; num_leaves=124; min_data_in_leaf=687; lambda_l1=0.708; lambda_l2=0.355 : y = 0.93 : 78.3 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 26 in the file bayesiana.RDATA.\n",
            "\n",
            "Sun Nov 02 11:29:27 PM 2025 AUC 0.92984780509463\n",
            "\n",
            "[mbo] 26: learning_rate=0.0103; num_iterations=822; feature_fraction=0.571; bagging_fraction=0.747; num_leaves=446; min_data_in_leaf=703; lambda_l1=0.32; lambda_l2=0.0928 : y = 0.93 : 191.3 secs : infill_ei\n",
            "\n",
            "Sun Nov 02 11:30:51 PM 2025 AUC 0.929464007207171\n",
            "\n",
            "[mbo] 27: learning_rate=0.0236; num_iterations=786; feature_fraction=0.598; bagging_fraction=0.81; num_leaves=510; min_data_in_leaf=689; lambda_l1=0.446; lambda_l2=0.373 : y = 0.929 : 83.7 secs : infill_ei\n",
            "\n",
            "Sun Nov 02 11:33:34 PM 2025 AUC 0.930199204821196\n",
            "\n",
            "[mbo] 28: learning_rate=0.0102; num_iterations=958; feature_fraction=0.704; bagging_fraction=0.821; num_leaves=106; min_data_in_leaf=393; lambda_l1=0.955; lambda_l2=0.316 : y = 0.93 : 161.8 secs : infill_ei\n",
            "\n",
            "Sun Nov 02 11:35:58 PM 2025 AUC 0.92918073013737\n",
            "\n",
            "[mbo] 29: learning_rate=0.0116; num_iterations=956; feature_fraction=0.676; bagging_fraction=0.782; num_leaves=118; min_data_in_leaf=927; lambda_l1=0.701; lambda_l2=0.0684 : y = 0.929 : 143.6 secs : infill_ei\n",
            "\n",
            "Sun Nov 02 11:38:36 PM 2025 AUC 0.930004221266957\n",
            "\n",
            "[mbo] 30: learning_rate=0.012; num_iterations=1433; feature_fraction=0.613; bagging_fraction=0.752; num_leaves=569; min_data_in_leaf=556; lambda_l1=0.814; lambda_l2=0.0617 : y = 0.93 : 157.6 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 31 in the file bayesiana.RDATA.\n",
            "\n",
            "Sun Nov 02 11:39:25 PM 2025 AUC 0.930069120393579\n",
            "\n",
            "[mbo] 31: learning_rate=0.0375; num_iterations=1032; feature_fraction=0.742; bagging_fraction=0.824; num_leaves=214; min_data_in_leaf=584; lambda_l1=0.855; lambda_l2=0.35 : y = 0.93 : 47.8 secs : infill_ei\n",
            "\n",
            "Sun Nov 02 11:41:56 PM 2025 AUC 0.929298663473638\n",
            "\n",
            "[mbo] 32: learning_rate=0.0102; num_iterations=1731; feature_fraction=0.647; bagging_fraction=0.731; num_leaves=752; min_data_in_leaf=642; lambda_l1=0.0997; lambda_l2=0.0296 : y = 0.929 : 150.1 secs : infill_ei\n",
            "\n",
            "Sun Nov 02 11:44:24 PM 2025 AUC 0.930148708873463\n",
            "\n",
            "[mbo] 33: learning_rate=0.0106; num_iterations=901; feature_fraction=0.687; bagging_fraction=0.805; num_leaves=162; min_data_in_leaf=672; lambda_l1=0.921; lambda_l2=0.336 : y = 0.93 : 147.6 secs : infill_ei\n",
            "\n",
            "Sun Nov 02 11:45:38 PM 2025 AUC 0.930714468501045\n",
            "\n",
            "[mbo] 34: learning_rate=0.0256; num_iterations=1155; feature_fraction=0.7; bagging_fraction=0.833; num_leaves=177; min_data_in_leaf=426; lambda_l1=0.952; lambda_l2=0.287 : y = 0.931 : 72.5 secs : infill_ei\n",
            "\n",
            "Sun Nov 02 11:47:18 PM 2025 AUC 0.929946322264259\n",
            "\n",
            "[mbo] 35: learning_rate=0.0262; num_iterations=1586; feature_fraction=0.535; bagging_fraction=0.757; num_leaves=249; min_data_in_leaf=698; lambda_l1=0.954; lambda_l2=0.289 : y = 0.93 : 99.7 secs : infill_ei\n",
            "\n",
            "Sun Nov 02 11:48:37 PM 2025 AUC 0.929527323328147\n",
            "\n",
            "[mbo] 36: learning_rate=0.0265; num_iterations=1413; feature_fraction=0.634; bagging_fraction=0.809; num_leaves=259; min_data_in_leaf=456; lambda_l1=0.772; lambda_l2=0.325 : y = 0.93 : 77.1 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 37 in the file bayesiana.RDATA.\n",
            "\n",
            "Sun Nov 02 11:51:59 PM 2025 AUC 0.928145341036305\n",
            "\n",
            "[mbo] 37: learning_rate=0.0103; num_iterations=1615; feature_fraction=0.589; bagging_fraction=0.722; num_leaves=399; min_data_in_leaf=1471; lambda_l1=0.962; lambda_l2=0.291 : y = 0.928 : 201.5 secs : infill_ei\n",
            "\n",
            "Sun Nov 02 11:53:25 PM 2025 AUC 0.930397856530864\n",
            "\n",
            "[mbo] 38: learning_rate=0.0224; num_iterations=991; feature_fraction=0.772; bagging_fraction=0.885; num_leaves=114; min_data_in_leaf=389; lambda_l1=0.999; lambda_l2=0.0651 : y = 0.93 : 85.0 secs : infill_ei\n",
            "\n",
            "Sun Nov 02 11:54:32 PM 2025 AUC 0.928879635670926\n",
            "\n",
            "[mbo] 39: learning_rate=0.0223; num_iterations=1062; feature_fraction=0.757; bagging_fraction=0.838; num_leaves=728; min_data_in_leaf=379; lambda_l1=0.954; lambda_l2=0.3 : y = 0.929 : 66.4 secs : infill_ei\n",
            "\n",
            "Sun Nov 02 11:57:01 PM 2025 AUC 0.930013695877365\n",
            "\n",
            "[mbo] 40: learning_rate=0.0116; num_iterations=1735; feature_fraction=0.59; bagging_fraction=0.831; num_leaves=133; min_data_in_leaf=713; lambda_l1=0.285; lambda_l2=0.0847 : y = 0.93 : 148.2 secs : infill_ei\n",
            "\n",
            "Mon Nov 03 12:01:35 AM 2025 AUC 0.929240800185419\n",
            "\n",
            "[mbo] 41: learning_rate=0.01; num_iterations=1818; feature_fraction=0.527; bagging_fraction=0.642; num_leaves=315; min_data_in_leaf=701; lambda_l1=0.386; lambda_l2=0.316 : y = 0.929 : 272.8 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 42 in the file bayesiana.RDATA.\n",
            "\n",
            "Mon Nov 03 12:03:37 AM 2025 AUC 0.928749951302159\n",
            "\n",
            "[mbo] 42: learning_rate=0.0173; num_iterations=1654; feature_fraction=0.57; bagging_fraction=0.823; num_leaves=144; min_data_in_leaf=262; lambda_l1=0.174; lambda_l2=0.404 : y = 0.929 : 121.3 secs : infill_ei\n",
            "\n",
            "Mon Nov 03 12:06:17 AM 2025 AUC 0.931273631565587\n",
            "\n",
            "[mbo] 43: learning_rate=0.0113; num_iterations=1119; feature_fraction=0.657; bagging_fraction=0.75; num_leaves=785; min_data_in_leaf=723; lambda_l1=0.984; lambda_l2=0.0373 : y = 0.931 : 159.0 secs : infill_ei\n",
            "\n",
            "Mon Nov 03 12:07:49 AM 2025 AUC 0.929784169945816\n",
            "\n",
            "[mbo] 44: learning_rate=0.023; num_iterations=1851; feature_fraction=0.751; bagging_fraction=0.69; num_leaves=736; min_data_in_leaf=727; lambda_l1=0.954; lambda_l2=0.0401 : y = 0.93 : 90.8 secs : infill_ei\n",
            "\n",
            "Mon Nov 03 12:10:17 AM 2025 AUC 0.929725944034703\n",
            "\n",
            "[mbo] 45: learning_rate=0.0101; num_iterations=1145; feature_fraction=0.705; bagging_fraction=0.747; num_leaves=997; min_data_in_leaf=735; lambda_l1=0.922; lambda_l2=0.103 : y = 0.93 : 147.6 secs : infill_ei\n",
            "\n",
            "Mon Nov 03 12:13:34 AM 2025 AUC 0.930516111699957\n",
            "\n",
            "[mbo] 46: learning_rate=0.0105; num_iterations=1183; feature_fraction=0.6; bagging_fraction=0.729; num_leaves=675; min_data_in_leaf=748; lambda_l1=0.974; lambda_l2=0.229 : y = 0.931 : 195.6 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 47 in the file bayesiana.RDATA.\n",
            "\n",
            "Mon Nov 03 12:14:44 AM 2025 AUC 0.928756439259575\n",
            "\n",
            "[mbo] 47: learning_rate=0.0384; num_iterations=1738; feature_fraction=0.589; bagging_fraction=0.697; num_leaves=763; min_data_in_leaf=727; lambda_l1=0.896; lambda_l2=0.0626 : y = 0.929 : 69.0 secs : infill_ei\n",
            "\n",
            "Mon Nov 03 12:16:56 AM 2025 AUC 0.928585809385696\n",
            "\n",
            "[mbo] 48: learning_rate=0.0234; num_iterations=734; feature_fraction=0.593; bagging_fraction=0.911; num_leaves=721; min_data_in_leaf=1664; lambda_l1=0.495; lambda_l2=0.0538 : y = 0.929 : 131.0 secs : infill_ei\n",
            "\n",
            "Mon Nov 03 12:17:43 AM 2025 AUC 0.929468463909976\n",
            "\n",
            "[mbo] 49: learning_rate=0.0453; num_iterations=1968; feature_fraction=0.722; bagging_fraction=0.883; num_leaves=71; min_data_in_leaf=779; lambda_l1=0.527; lambda_l2=0.15 : y = 0.929 : 46.2 secs : infill_ei\n",
            "\n",
            "Mon Nov 03 12:20:00 AM 2025 AUC 0.928344618532197\n",
            "\n",
            "[mbo] 50: learning_rate=0.0129; num_iterations=823; feature_fraction=0.61; bagging_fraction=0.62; num_leaves=827; min_data_in_leaf=738; lambda_l1=0.899; lambda_l2=0.00151 : y = 0.928 : 136.2 secs : infill_ei\n",
            "\n",
            "Mon Nov 03 12:22:58 AM 2025 AUC 0.930073645811272\n",
            "\n",
            "[mbo] 51: learning_rate=0.0101; num_iterations=1120; feature_fraction=0.625; bagging_fraction=0.805; num_leaves=777; min_data_in_leaf=829; lambda_l1=0.979; lambda_l2=0.193 : y = 0.93 : 176.8 secs : infill_ei\n",
            "\n",
            "Mon Nov 03 12:24:14 AM 2025 AUC 0.929864542371545\n",
            "\n",
            "[mbo] 52: learning_rate=0.0235; num_iterations=574; feature_fraction=0.74; bagging_fraction=0.739; num_leaves=743; min_data_in_leaf=697; lambda_l1=0.989; lambda_l2=0.00417 : y = 0.93 : 74.9 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 53 in the file bayesiana.RDATA.\n",
            "\n",
            "Mon Nov 03 12:28:36 AM 2025 AUC 0.930655863858972\n",
            "\n",
            "[mbo] 53: learning_rate=0.0101; num_iterations=1765; feature_fraction=0.528; bagging_fraction=0.782; num_leaves=356; min_data_in_leaf=781; lambda_l1=0.0412; lambda_l2=0.628 : y = 0.931 : 261.5 secs : infill_ei\n",
            "\n",
            "Mon Nov 03 12:30:39 AM 2025 AUC 0.929527548348766\n",
            "\n",
            "[mbo] 54: learning_rate=0.0208; num_iterations=1932; feature_fraction=0.584; bagging_fraction=0.817; num_leaves=101; min_data_in_leaf=709; lambda_l1=0.087; lambda_l2=0.715 : y = 0.93 : 121.4 secs : infill_ei\n",
            "\n",
            "Mon Nov 03 12:31:48 AM 2025 AUC 0.92940408970209\n",
            "\n",
            "[mbo] 55: learning_rate=0.0257; num_iterations=531; feature_fraction=0.808; bagging_fraction=0.884; num_leaves=64; min_data_in_leaf=559; lambda_l1=0.341; lambda_l2=0.134 : y = 0.929 : 67.2 secs : infill_ei\n",
            "\n",
            "Mon Nov 03 12:33:06 AM 2025 AUC 0.930225187384356\n",
            "\n",
            "[mbo] 56: learning_rate=0.024; num_iterations=1127; feature_fraction=0.704; bagging_fraction=0.952; num_leaves=65; min_data_in_leaf=643; lambda_l1=0.981; lambda_l2=0.175 : y = 0.93 : 77.4 secs : infill_ei\n",
            "\n",
            "Mon Nov 03 12:35:16 AM 2025 AUC 0.93011987085857\n",
            "\n",
            "[mbo] 57: learning_rate=0.0112; num_iterations=1508; feature_fraction=0.711; bagging_fraction=0.88; num_leaves=95; min_data_in_leaf=797; lambda_l1=0.225; lambda_l2=0.0685 : y = 0.93 : 128.3 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 58 in the file bayesiana.RDATA.\n",
            "\n",
            "Mon Nov 03 12:38:51 AM 2025 AUC 0.929550967857575\n",
            "\n",
            "[mbo] 58: learning_rate=0.0101; num_iterations=886; feature_fraction=0.516; bagging_fraction=0.755; num_leaves=272; min_data_in_leaf=702; lambda_l1=0.8; lambda_l2=0.873 : y = 0.93 : 213.6 secs : infill_ei\n",
            "\n",
            "Mon Nov 03 12:39:41 AM 2025 AUC 0.928362497649535\n",
            "\n",
            "[mbo] 59: learning_rate=0.0491; num_iterations=635; feature_fraction=0.813; bagging_fraction=0.972; num_leaves=80; min_data_in_leaf=2056; lambda_l1=0.103; lambda_l2=0.705 : y = 0.928 : 49.7 secs : infill_ei\n",
            "\n",
            "Mon Nov 03 12:40:50 AM 2025 AUC 0.929719833934236\n",
            "\n",
            "[mbo] 60: learning_rate=0.0283; num_iterations=826; feature_fraction=0.7; bagging_fraction=0.902; num_leaves=86; min_data_in_leaf=707; lambda_l1=0.999; lambda_l2=0.512 : y = 0.93 : 67.7 secs : infill_ei\n",
            "\n",
            "Mon Nov 03 12:42:04 AM 2025 AUC 0.927712866113912\n",
            "\n",
            "[mbo] 61: learning_rate=0.0299; num_iterations=1834; feature_fraction=0.641; bagging_fraction=0.75; num_leaves=263; min_data_in_leaf=776; lambda_l1=0.313; lambda_l2=0.36 : y = 0.928 : 73.6 secs : infill_ei\n",
            "\n",
            "Mon Nov 03 12:42:56 AM 2025 AUC 0.928880665981686\n",
            "\n",
            "[mbo] 62: learning_rate=0.0495; num_iterations=1085; feature_fraction=0.673; bagging_fraction=0.894; num_leaves=297; min_data_in_leaf=582; lambda_l1=0.896; lambda_l2=0.147 : y = 0.929 : 50.9 secs : infill_ei\n",
            "\n",
            "Mon Nov 03 12:45:18 AM 2025 AUC 0.9296306619897\n",
            "\n",
            "[mbo] 63: learning_rate=0.01; num_iterations=766; feature_fraction=0.659; bagging_fraction=0.859; num_leaves=305; min_data_in_leaf=672; lambda_l1=0.0938; lambda_l2=0.74 : y = 0.93 : 140.9 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 64 in the file bayesiana.RDATA.\n",
            "\n",
            "Mon Nov 03 12:46:30 AM 2025 AUC 0.929874854620946\n",
            "\n",
            "[mbo] 64: learning_rate=0.0441; num_iterations=1700; feature_fraction=0.52; bagging_fraction=0.786; num_leaves=148; min_data_in_leaf=631; lambda_l1=0.985; lambda_l2=0.177 : y = 0.93 : 70.8 secs : infill_ei\n",
            "\n",
            "Mon Nov 03 12:51:26 AM 2025 AUC 0.929193406179126\n",
            "\n",
            "[mbo] 65: learning_rate=0.01; num_iterations=1184; feature_fraction=0.52; bagging_fraction=0.807; num_leaves=103; min_data_in_leaf=857; lambda_l1=0.0734; lambda_l2=0.2 : y = 0.929 : 294.9 secs : infill_ei\n",
            "\n",
            "Mon Nov 03 12:54:02 AM 2025 AUC 0.9303765155842\n",
            "\n",
            "[mbo] 66: learning_rate=0.01; num_iterations=908; feature_fraction=0.648; bagging_fraction=0.947; num_leaves=173; min_data_in_leaf=709; lambda_l1=0.433; lambda_l2=0.364 : y = 0.93 : 155.4 secs : infill_ei\n",
            "\n",
            "Mon Nov 03 12:55:00 AM 2025 AUC 0.92752159635794\n",
            "\n",
            "[mbo] 67: learning_rate=0.0415; num_iterations=1235; feature_fraction=0.658; bagging_fraction=0.943; num_leaves=179; min_data_in_leaf=1760; lambda_l1=0.871; lambda_l2=0.0942 : y = 0.928 : 56.2 secs : infill_ei\n",
            "\n",
            "Mon Nov 03 12:57:35 AM 2025 AUC 0.930532227596881\n",
            "\n",
            "[mbo] 68: learning_rate=0.0101; num_iterations=1622; feature_fraction=0.738; bagging_fraction=0.95; num_leaves=102; min_data_in_leaf=721; lambda_l1=0.284; lambda_l2=0.771 : y = 0.931 : 154.0 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 69 in the file bayesiana.RDATA.\n",
            "\n",
            "Mon Nov 03 12:59:08 AM 2025 AUC 0.93031950976265\n",
            "\n",
            "[mbo] 69: learning_rate=0.0218; num_iterations=950; feature_fraction=0.65; bagging_fraction=0.736; num_leaves=866; min_data_in_leaf=694; lambda_l1=0.994; lambda_l2=0.254 : y = 0.93 : 91.7 secs : infill_ei\n",
            "\n",
            "Mon Nov 03 01:02:41 AM 2025 AUC 0.930970219741382\n",
            "\n",
            "[mbo] 70: learning_rate=0.01; num_iterations=1925; feature_fraction=0.554; bagging_fraction=0.9; num_leaves=502; min_data_in_leaf=531; lambda_l1=0.0221; lambda_l2=0.6 : y = 0.931 : 212.1 secs : infill_ei\n",
            "\n",
            "Mon Nov 03 01:06:26 AM 2025 AUC 0.927142862314918\n",
            "\n",
            "[mbo] 71: learning_rate=0.0101; num_iterations=1790; feature_fraction=0.633; bagging_fraction=0.934; num_leaves=175; min_data_in_leaf=2258; lambda_l1=0.00482; lambda_l2=0.635 : y = 0.927 : 223.7 secs : infill_ei\n",
            "\n",
            "Mon Nov 03 01:07:46 AM 2025 AUC 0.930281300372834\n",
            "\n",
            "[mbo] 72: learning_rate=0.0236; num_iterations=1091; feature_fraction=0.654; bagging_fraction=0.743; num_leaves=187; min_data_in_leaf=612; lambda_l1=0.999; lambda_l2=0.195 : y = 0.93 : 78.9 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 73 in the file bayesiana.RDATA.\n",
            "\n",
            "Mon Nov 03 01:11:41 AM 2025 AUC 0.930125334020689\n",
            "\n",
            "[mbo] 73: learning_rate=0.0101; num_iterations=1691; feature_fraction=0.53; bagging_fraction=0.894; num_leaves=303; min_data_in_leaf=690; lambda_l1=0.75; lambda_l2=0.694 : y = 0.93 : 234.0 secs : infill_ei\n",
            "\n",
            "Mon Nov 03 01:14:33 AM 2025 AUC 0.92897613245856\n",
            "\n",
            "[mbo] 74: learning_rate=0.0101; num_iterations=1889; feature_fraction=0.623; bagging_fraction=0.953; num_leaves=277; min_data_in_leaf=694; lambda_l1=0.163; lambda_l2=0.578 : y = 0.929 : 170.4 secs : infill_ei\n",
            "\n",
            "Mon Nov 03 01:18:26 AM 2025 AUC 0.930082114056982\n",
            "\n",
            "[mbo] 75: learning_rate=0.0106; num_iterations=1964; feature_fraction=0.512; bagging_fraction=0.8; num_leaves=695; min_data_in_leaf=222; lambda_l1=0.725; lambda_l2=0.619 : y = 0.93 : 232.3 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 76 in the file bayesiana.RDATA.\n",
            "\n",
            "Mon Nov 03 01:22:18 AM 2025 AUC 0.930804247982614\n",
            "\n",
            "[mbo] 76: learning_rate=0.0101; num_iterations=1585; feature_fraction=0.526; bagging_fraction=0.788; num_leaves=801; min_data_in_leaf=605; lambda_l1=0.811; lambda_l2=0.465 : y = 0.931 : 231.0 secs : infill_ei\n",
            "\n",
            "Mon Nov 03 01:25:54 AM 2025 AUC 0.93011798213594\n",
            "\n",
            "[mbo] 77: learning_rate=0.01; num_iterations=1904; feature_fraction=0.544; bagging_fraction=0.818; num_leaves=934; min_data_in_leaf=712; lambda_l1=0.219; lambda_l2=0.885 : y = 0.93 : 214.3 secs : infill_ei\n",
            "\n",
            "Mon Nov 03 01:29:39 AM 2025 AUC 0.930320428820639\n",
            "\n",
            "[mbo] 78: learning_rate=0.0102; num_iterations=1392; feature_fraction=0.504; bagging_fraction=0.919; num_leaves=581; min_data_in_leaf=627; lambda_l1=0.373; lambda_l2=0.297 : y = 0.93 : 224.5 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 79 in the file bayesiana.RDATA.\n",
            "\n",
            "Mon Nov 03 01:33:57 AM 2025 AUC 0.929943123909222\n",
            "\n",
            "[mbo] 79: learning_rate=0.0101; num_iterations=1710; feature_fraction=0.509; bagging_fraction=0.916; num_leaves=707; min_data_in_leaf=623; lambda_l1=0.0141; lambda_l2=0.687 : y = 0.93 : 256.4 secs : infill_ei\n",
            "\n",
            "Mon Nov 03 01:38:06 AM 2025 AUC 0.929677906042571\n",
            "\n",
            "[mbo] 80: learning_rate=0.0103; num_iterations=1558; feature_fraction=0.514; bagging_fraction=0.849; num_leaves=498; min_data_in_leaf=707; lambda_l1=0.72; lambda_l2=0.72 : y = 0.93 : 247.7 secs : infill_ei\n",
            "\n",
            "Mon Nov 03 01:41:48 AM 2025 AUC 0.929618986259629\n",
            "\n",
            "[mbo] 81: learning_rate=0.01; num_iterations=1619; feature_fraction=0.531; bagging_fraction=0.798; num_leaves=774; min_data_in_leaf=273; lambda_l1=0.5; lambda_l2=0.308 : y = 0.93 : 221.2 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 82 in the file bayesiana.RDATA.\n",
            "\n",
            "Mon Nov 03 01:45:38 AM 2025 AUC 0.92995975912487\n",
            "\n",
            "[mbo] 82: learning_rate=0.0103; num_iterations=1185; feature_fraction=0.558; bagging_fraction=0.76; num_leaves=823; min_data_in_leaf=435; lambda_l1=0.238; lambda_l2=0.529 : y = 0.93 : 228.2 secs : infill_ei\n",
            "\n",
            "Mon Nov 03 01:47:04 AM 2025 AUC 0.929538102623884\n",
            "\n",
            "[mbo] 83: learning_rate=0.0172; num_iterations=1576; feature_fraction=0.734; bagging_fraction=0.911; num_leaves=63; min_data_in_leaf=461; lambda_l1=0.628; lambda_l2=0.275 : y = 0.93 : 84.4 secs : infill_ei\n",
            "\n",
            "Mon Nov 03 01:48:15 AM 2025 AUC 0.928966634800462\n",
            "\n",
            "[mbo] 84: learning_rate=0.0456; num_iterations=1946; feature_fraction=0.572; bagging_fraction=0.759; num_leaves=182; min_data_in_leaf=417; lambda_l1=0.979; lambda_l2=0.568 : y = 0.929 : 70.1 secs : infill_ei\n",
            "\n",
            "Mon Nov 03 01:50:53 AM 2025 AUC 0.930364655809174\n",
            "\n",
            "[mbo] 85: learning_rate=0.0103; num_iterations=1237; feature_fraction=0.721; bagging_fraction=0.918; num_leaves=118; min_data_in_leaf=674; lambda_l1=0.328; lambda_l2=0.833 : y = 0.93 : 155.4 secs : infill_ei\n",
            "\n",
            "Mon Nov 03 01:52:09 AM 2025 AUC 0.929377462553248\n",
            "\n",
            "[mbo] 86: learning_rate=0.0248; num_iterations=901; feature_fraction=0.713; bagging_fraction=0.85; num_leaves=64; min_data_in_leaf=336; lambda_l1=0.916; lambda_l2=0.0143 : y = 0.929 : 74.9 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 87 in the file bayesiana.RDATA.\n",
            "\n",
            "Mon Nov 03 01:55:32 AM 2025 AUC 0.93021132829279\n",
            "\n",
            "[mbo] 87: learning_rate=0.013; num_iterations=1739; feature_fraction=0.506; bagging_fraction=0.744; num_leaves=801; min_data_in_leaf=679; lambda_l1=0.999; lambda_l2=0.211 : y = 0.93 : 201.2 secs : infill_ei\n",
            "\n",
            "Mon Nov 03 01:56:41 AM 2025 AUC 0.929724787431968\n",
            "\n",
            "[mbo] 88: learning_rate=0.0231; num_iterations=1319; feature_fraction=0.76; bagging_fraction=0.845; num_leaves=85; min_data_in_leaf=707; lambda_l1=0.439; lambda_l2=0.147 : y = 0.93 : 68.2 secs : infill_ei\n",
            "\n",
            "Mon Nov 03 02:00:08 AM 2025 AUC 0.930123636048346\n",
            "\n",
            "[mbo] 89: learning_rate=0.0106; num_iterations=1954; feature_fraction=0.583; bagging_fraction=0.749; num_leaves=824; min_data_in_leaf=680; lambda_l1=0.948; lambda_l2=0.698 : y = 0.93 : 205.6 secs : infill_ei\n",
            "\n",
            "Mon Nov 03 02:03:13 AM 2025 AUC 0.929509922594685\n",
            "\n",
            "[mbo] 90: learning_rate=0.0108; num_iterations=1988; feature_fraction=0.535; bagging_fraction=0.867; num_leaves=733; min_data_in_leaf=550; lambda_l1=0.258; lambda_l2=0.445 : y = 0.93 : 183.3 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 91 in the file bayesiana.RDATA.\n",
            "\n",
            "Mon Nov 03 02:07:23 AM 2025 AUC 0.930812428586874\n",
            "\n",
            "[mbo] 91: learning_rate=0.0113; num_iterations=1113; feature_fraction=0.511; bagging_fraction=0.768; num_leaves=900; min_data_in_leaf=712; lambda_l1=0.982; lambda_l2=0.34 : y = 0.931 : 248.5 secs : infill_ei\n",
            "\n",
            "Mon Nov 03 02:08:59 AM 2025 AUC 0.928646571220138\n",
            "\n",
            "[mbo] 92: learning_rate=0.0229; num_iterations=549; feature_fraction=0.803; bagging_fraction=0.975; num_leaves=253; min_data_in_leaf=283; lambda_l1=0.777; lambda_l2=0.313 : y = 0.929 : 94.2 secs : infill_ei\n",
            "\n",
            "Mon Nov 03 02:12:32 AM 2025 AUC 0.92961932889218\n",
            "\n",
            "[mbo] 93: learning_rate=0.01; num_iterations=961; feature_fraction=0.569; bagging_fraction=0.756; num_leaves=865; min_data_in_leaf=721; lambda_l1=0.764; lambda_l2=0.0138 : y = 0.93 : 211.8 secs : infill_ei\n",
            "\n",
            "Mon Nov 03 02:14:43 AM 2025 AUC 0.92887354092734\n",
            "\n",
            "[mbo] 94: learning_rate=0.0154; num_iterations=914; feature_fraction=0.787; bagging_fraction=0.898; num_leaves=69; min_data_in_leaf=263; lambda_l1=0.508; lambda_l2=0.762 : y = 0.929 : 130.1 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 95 in the file bayesiana.RDATA.\n",
            "\n",
            "Mon Nov 03 02:17:54 AM 2025 AUC 0.93039734907822\n",
            "\n",
            "[mbo] 95: learning_rate=0.0154; num_iterations=853; feature_fraction=0.515; bagging_fraction=0.778; num_leaves=899; min_data_in_leaf=606; lambda_l1=0.923; lambda_l2=0.798 : y = 0.93 : 189.6 secs : infill_ei\n",
            "\n",
            "Mon Nov 03 02:22:01 AM 2025 AUC 0.930727428268376\n",
            "\n",
            "[mbo] 96: learning_rate=0.0103; num_iterations=1278; feature_fraction=0.548; bagging_fraction=0.762; num_leaves=733; min_data_in_leaf=621; lambda_l1=0.84; lambda_l2=0.595 : y = 0.931 : 244.7 secs : infill_ei\n",
            "\n",
            "Mon Nov 03 02:25:48 AM 2025 AUC 0.930095652672565\n",
            "\n",
            "[mbo] 97: learning_rate=0.01; num_iterations=1198; feature_fraction=0.556; bagging_fraction=0.937; num_leaves=182; min_data_in_leaf=631; lambda_l1=0.213; lambda_l2=0.544 : y = 0.93 : 226.4 secs : infill_ei\n",
            "\n",
            "Saved the current state after iteration 98 in the file bayesiana.RDATA.\n",
            "\n",
            "Mon Nov 03 02:28:43 AM 2025 AUC 0.929475741565764\n",
            "\n",
            "[mbo] 98: learning_rate=0.0126; num_iterations=1189; feature_fraction=0.541; bagging_fraction=0.774; num_leaves=338; min_data_in_leaf=520; lambda_l1=0.017; lambda_l2=0.813 : y = 0.929 : 172.7 secs : infill_ei\n",
            "\n",
            "Mon Nov 03 02:30:27 AM 2025 AUC 0.927880731253449\n",
            "\n",
            "[mbo] 99: learning_rate=0.0332; num_iterations=690; feature_fraction=0.502; bagging_fraction=0.743; num_leaves=651; min_data_in_leaf=693; lambda_l1=0.809; lambda_l2=0.319 : y = 0.928 : 103.1 secs : infill_ei\n",
            "\n",
            "Mon Nov 03 02:33:03 AM 2025 AUC 0.930738412847829\n",
            "\n",
            "[mbo] 100: learning_rate=0.01; num_iterations=1545; feature_fraction=0.694; bagging_fraction=0.931; num_leaves=150; min_data_in_leaf=427; lambda_l1=0.181; lambda_l2=0.988 : y = 0.931 : 155.0 secs : infill_ei\n",
            "\n",
            "Saved the final state in the file bayesiana.RDATA\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "tb_bayesiana <- as.data.table(bayesiana_salida$opt.path)\n",
        "colnames( tb_bayesiana)"
      ],
      "metadata": {
        "id": "ssk5nnMk6INK",
        "outputId": "fb1f4a35-ee86-4364-c975-3f26c300e9d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>'learning_rate'</li><li>'num_iterations'</li><li>'feature_fraction'</li><li>'bagging_fraction'</li><li>'num_leaves'</li><li>'min_data_in_leaf'</li><li>'lambda_l1'</li><li>'lambda_l2'</li><li>'y'</li><li>'dob'</li><li>'eol'</li><li>'error.message'</li><li>'exec.time'</li><li>'ei'</li><li>'error.model'</li><li>'train.time'</li><li>'prop.type'</li><li>'propose.time'</li><li>'se'</li><li>'mean'</li></ol>\n"
            ],
            "text/markdown": "1. 'learning_rate'\n2. 'num_iterations'\n3. 'feature_fraction'\n4. 'bagging_fraction'\n5. 'num_leaves'\n6. 'min_data_in_leaf'\n7. 'lambda_l1'\n8. 'lambda_l2'\n9. 'y'\n10. 'dob'\n11. 'eol'\n12. 'error.message'\n13. 'exec.time'\n14. 'ei'\n15. 'error.model'\n16. 'train.time'\n17. 'prop.type'\n18. 'propose.time'\n19. 'se'\n20. 'mean'\n\n\n",
            "text/latex": "\\begin{enumerate*}\n\\item 'learning\\_rate'\n\\item 'num\\_iterations'\n\\item 'feature\\_fraction'\n\\item 'bagging\\_fraction'\n\\item 'num\\_leaves'\n\\item 'min\\_data\\_in\\_leaf'\n\\item 'lambda\\_l1'\n\\item 'lambda\\_l2'\n\\item 'y'\n\\item 'dob'\n\\item 'eol'\n\\item 'error.message'\n\\item 'exec.time'\n\\item 'ei'\n\\item 'error.model'\n\\item 'train.time'\n\\item 'prop.type'\n\\item 'propose.time'\n\\item 'se'\n\\item 'mean'\n\\end{enumerate*}\n",
            "text/plain": [
              " [1] \"learning_rate\"    \"num_iterations\"   \"feature_fraction\" \"bagging_fraction\"\n",
              " [5] \"num_leaves\"       \"min_data_in_leaf\" \"lambda_l1\"        \"lambda_l2\"       \n",
              " [9] \"y\"                \"dob\"              \"eol\"              \"error.message\"   \n",
              "[13] \"exec.time\"        \"ei\"               \"error.model\"      \"train.time\"      \n",
              "[17] \"prop.type\"        \"propose.time\"     \"se\"               \"mean\"            "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# almaceno los resultados de la Bayesian Optimization\n",
        "# y capturo los mejores hiperparametros encontrados\n",
        "\n",
        "tb_bayesiana <- as.data.table(bayesiana_salida$opt.path)\n",
        "\n",
        "tb_bayesiana[, iter := .I]\n",
        "\n",
        "# ordeno en forma descendente por AUC = y\n",
        "setorder(tb_bayesiana, -y)\n",
        "\n",
        "# grabo para eventualmente poder utilizarlos en OTRA corrida\n",
        "fwrite( tb_bayesiana,\n",
        "  file= \"BO_log.txt\",\n",
        "  sep= \"\\t\"\n",
        ")\n",
        "\n",
        "# los mejores hiperparámetros son los que quedaron en el registro 1 de la tabla\n",
        "PARAM$out$lgbm$mejores_hiperparametros <- tb_bayesiana[\n",
        "  1, # el primero es el de mejor AUC\n",
        "  setdiff(colnames(tb_bayesiana),\n",
        "    c(\"y\",\"dob\",\"eol\",\"error.message\",\"exec.time\",\"ei\",\"error.model\",\n",
        "      \"train.time\",\"prop.type\",\"propose.time\",\"se\",\"mean\",\"iter\")),\n",
        "  with= FALSE\n",
        "]\n",
        "\n",
        "\n",
        "PARAM$out$lgbm$y <- tb_bayesiana[1, y]\n"
      ],
      "metadata": {
        "id": "u4zq-vknhjGc"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "write_yaml( PARAM, file=\"PARAM.yml\")"
      ],
      "metadata": {
        "id": "E8v2eA427N8e"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(PARAM$out$lgbm$mejores_hiperparametros)\n",
        "print(PARAM$out$lgbm$y)"
      ],
      "metadata": {
        "id": "iBTWexVU7PGC",
        "outputId": "41094fa9-ad4d-45f1-a363-9cbc20d4ac9f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   learning_rate num_iterations feature_fraction bagging_fraction num_leaves\n",
            "           <num>          <int>            <num>            <num>      <int>\n",
            "1:    0.01131726           1119        0.6565776        0.7496957        785\n",
            "   min_data_in_leaf lambda_l1  lambda_l2\n",
            "              <int>     <num>      <num>\n",
            "1:              723 0.9842552 0.03728389\n",
            "[1] 0.9312736\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.3  Produccion"
      ],
      "metadata": {
        "id": "TKsVZmAnhwX-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Final Training\n",
        "Construyo el modelo final, que es uno solo, no hace ningun tipo de particion < training, validation, testing>]"
      ],
      "metadata": {
        "id": "RQ_C33Tr5B_9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "setwd(\"/content/buckets/b1/exp\")\n",
        "experimento <- paste0(\"exp\", PARAM$experimento)\n",
        "dir.create(experimento, showWarnings= FALSE)\n",
        "setwd( paste0(\"/content/buckets/b1/exp/\", experimento ))"
      ],
      "metadata": {
        "id": "eDqfyA14hzwv"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Final Training Dataset\n",
        "\n",
        "Aqui esta la gran decision de en qué meses hago el Final Training\n",
        "<br> debo utilizar los mejores hiperparámetros que encontré en la optimización bayesiana"
      ],
      "metadata": {
        "id": "8qFmFivf5Iet"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# clase01\n",
        "dataset[, clase01 := ifelse(clase_ternaria %in% c(\"BAJA+1\", \"BAJA+2\"), 1L, 0L)]"
      ],
      "metadata": {
        "id": "lg5WVZncvc7H"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_train <- dataset[foto_mes %in% c(202107)]"
      ],
      "metadata": {
        "id": "yc9QzXREv0xf"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dejo los datos en el formato que necesita LightGBM\n",
        "\n",
        "dtrain <- lgb.Dataset(\n",
        "  data= data.matrix(dataset_train[, campos_buenos, with= FALSE]),\n",
        "  label= dataset_train[, clase01]\n",
        ")"
      ],
      "metadata": {
        "id": "thjdqEBLuvNt"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Final Training Hyperparameters"
      ],
      "metadata": {
        "id": "VNUa-WSz5Oqu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_final <- modifyList(PARAM$lgbm$param_fijos,\n",
        "  PARAM$out$lgbm$mejores_hiperparametros)\n",
        "\n",
        "param_final"
      ],
      "metadata": {
        "id": "FgCcvBfEwImu",
        "outputId": "b96a94fd-ac4a-434e-c3e7-80ed3680a2e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 877
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<dl>\n",
              "\t<dt>$boosting</dt>\n",
              "\t\t<dd>'gbdt'</dd>\n",
              "\t<dt>$objective</dt>\n",
              "\t\t<dd>'binary'</dd>\n",
              "\t<dt>$metric</dt>\n",
              "\t\t<dd>'auc'</dd>\n",
              "\t<dt>$first_metric_only</dt>\n",
              "\t\t<dd>TRUE</dd>\n",
              "\t<dt>$boost_from_average</dt>\n",
              "\t\t<dd>TRUE</dd>\n",
              "\t<dt>$feature_pre_filter</dt>\n",
              "\t\t<dd>FALSE</dd>\n",
              "\t<dt>$force_row_wise</dt>\n",
              "\t\t<dd>TRUE</dd>\n",
              "\t<dt>$verbosity</dt>\n",
              "\t\t<dd>-100</dd>\n",
              "\t<dt>$seed</dt>\n",
              "\t\t<dd>100019</dd>\n",
              "\t<dt>$lambda_l1</dt>\n",
              "\t\t<dd>0.984255162859109</dd>\n",
              "\t<dt>$lambda_l2</dt>\n",
              "\t\t<dd>0.0372838854953916</dd>\n",
              "\t<dt>$min_gain_to_split</dt>\n",
              "\t\t<dd>0</dd>\n",
              "\t<dt>$min_sum_hessian_in_leaf</dt>\n",
              "\t\t<dd>0.001</dd>\n",
              "\t<dt>$max_bin</dt>\n",
              "\t\t<dd>31</dd>\n",
              "\t<dt>$bagging_freq</dt>\n",
              "\t\t<dd>1</dd>\n",
              "\t<dt>$is_unbalance</dt>\n",
              "\t\t<dd>FALSE</dd>\n",
              "\t<dt>$scale_pos_weight</dt>\n",
              "\t\t<dd>1</dd>\n",
              "\t<dt>$num_iterations</dt>\n",
              "\t\t<dd>1119</dd>\n",
              "\t<dt>$learning_rate</dt>\n",
              "\t\t<dd>0.0113172644257655</dd>\n",
              "\t<dt>$feature_fraction</dt>\n",
              "\t\t<dd>0.656577568864892</dd>\n",
              "\t<dt>$num_leaves</dt>\n",
              "\t\t<dd>785</dd>\n",
              "\t<dt>$min_data_in_leaf</dt>\n",
              "\t\t<dd>723</dd>\n",
              "\t<dt>$max_depth</dt>\n",
              "\t\t<dd>-1</dd>\n",
              "\t<dt>$bagging_fraction</dt>\n",
              "\t\t<dd>0.749695698297183</dd>\n",
              "</dl>\n"
            ],
            "text/markdown": "$boosting\n:   'gbdt'\n$objective\n:   'binary'\n$metric\n:   'auc'\n$first_metric_only\n:   TRUE\n$boost_from_average\n:   TRUE\n$feature_pre_filter\n:   FALSE\n$force_row_wise\n:   TRUE\n$verbosity\n:   -100\n$seed\n:   100019\n$lambda_l1\n:   0.984255162859109\n$lambda_l2\n:   0.0372838854953916\n$min_gain_to_split\n:   0\n$min_sum_hessian_in_leaf\n:   0.001\n$max_bin\n:   31\n$bagging_freq\n:   1\n$is_unbalance\n:   FALSE\n$scale_pos_weight\n:   1\n$num_iterations\n:   1119\n$learning_rate\n:   0.0113172644257655\n$feature_fraction\n:   0.656577568864892\n$num_leaves\n:   785\n$min_data_in_leaf\n:   723\n$max_depth\n:   -1\n$bagging_fraction\n:   0.749695698297183\n\n\n",
            "text/latex": "\\begin{description}\n\\item[\\$boosting] 'gbdt'\n\\item[\\$objective] 'binary'\n\\item[\\$metric] 'auc'\n\\item[\\$first\\_metric\\_only] TRUE\n\\item[\\$boost\\_from\\_average] TRUE\n\\item[\\$feature\\_pre\\_filter] FALSE\n\\item[\\$force\\_row\\_wise] TRUE\n\\item[\\$verbosity] -100\n\\item[\\$seed] 100019\n\\item[\\$lambda\\_l1] 0.984255162859109\n\\item[\\$lambda\\_l2] 0.0372838854953916\n\\item[\\$min\\_gain\\_to\\_split] 0\n\\item[\\$min\\_sum\\_hessian\\_in\\_leaf] 0.001\n\\item[\\$max\\_bin] 31\n\\item[\\$bagging\\_freq] 1\n\\item[\\$is\\_unbalance] FALSE\n\\item[\\$scale\\_pos\\_weight] 1\n\\item[\\$num\\_iterations] 1119\n\\item[\\$learning\\_rate] 0.0113172644257655\n\\item[\\$feature\\_fraction] 0.656577568864892\n\\item[\\$num\\_leaves] 785\n\\item[\\$min\\_data\\_in\\_leaf] 723\n\\item[\\$max\\_depth] -1\n\\item[\\$bagging\\_fraction] 0.749695698297183\n\\end{description}\n",
            "text/plain": [
              "$boosting\n",
              "[1] \"gbdt\"\n",
              "\n",
              "$objective\n",
              "[1] \"binary\"\n",
              "\n",
              "$metric\n",
              "[1] \"auc\"\n",
              "\n",
              "$first_metric_only\n",
              "[1] TRUE\n",
              "\n",
              "$boost_from_average\n",
              "[1] TRUE\n",
              "\n",
              "$feature_pre_filter\n",
              "[1] FALSE\n",
              "\n",
              "$force_row_wise\n",
              "[1] TRUE\n",
              "\n",
              "$verbosity\n",
              "[1] -100\n",
              "\n",
              "$seed\n",
              "[1] 100019\n",
              "\n",
              "$lambda_l1\n",
              "[1] 0.9842552\n",
              "\n",
              "$lambda_l2\n",
              "[1] 0.03728389\n",
              "\n",
              "$min_gain_to_split\n",
              "[1] 0\n",
              "\n",
              "$min_sum_hessian_in_leaf\n",
              "[1] 0.001\n",
              "\n",
              "$max_bin\n",
              "[1] 31\n",
              "\n",
              "$bagging_freq\n",
              "[1] 1\n",
              "\n",
              "$is_unbalance\n",
              "[1] FALSE\n",
              "\n",
              "$scale_pos_weight\n",
              "[1] 1\n",
              "\n",
              "$num_iterations\n",
              "[1] 1119\n",
              "\n",
              "$learning_rate\n",
              "[1] 0.01131726\n",
              "\n",
              "$feature_fraction\n",
              "[1] 0.6565776\n",
              "\n",
              "$num_leaves\n",
              "[1] 785\n",
              "\n",
              "$min_data_in_leaf\n",
              "[1] 723\n",
              "\n",
              "$max_depth\n",
              "[1] -1\n",
              "\n",
              "$bagging_fraction\n",
              "[1] 0.7496957\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Training\n",
        "Genero el modelo final, siempre sobre TODOS los datos de  final_train, sin hacer ningun tipo de undersampling de la clase mayoritaria"
      ],
      "metadata": {
        "id": "TZIYn4l95TBH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# este punto es muy SUTIL  y será revisado en la Clase 05\n",
        "\n",
        "param_normalizado <- copy(param_final)\n",
        "param_normalizado$min_data_in_leaf <-  round(param_final$min_data_in_leaf / PARAM$trainingstrategy$undersampling)"
      ],
      "metadata": {
        "id": "vPLsd4mMRe4u"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  # entreno LightGBM\n",
        "\n",
        "  modelo_final <- lgb.train(\n",
        "    data= dtrain,\n",
        "    param= param_normalizado\n",
        "  )"
      ],
      "metadata": {
        "id": "WRI_-taRwOXO"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ahora imprimo la importancia de variables\n",
        "\n",
        "tb_importancia <- as.data.table(lgb.importance(modelo_final))\n",
        "archivo_importancia <- \"impo.txt\"\n",
        "\n",
        "fwrite(tb_importancia,\n",
        "  file= archivo_importancia,\n",
        "  sep= \"\\t\"\n",
        ")"
      ],
      "metadata": {
        "id": "_bkhnCvj0g3Q"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# grabo a disco el modelo en un formato para seres humanos ... ponele ...\n",
        "\n",
        "lgb.save(modelo_final, \"modelo.txt\" )"
      ],
      "metadata": {
        "id": "lZ3sLmbh0kFj"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Scoring"
      ],
      "metadata": {
        "id": "VEtp2--t5Ymg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aplico el modelo final a los datos del futuro"
      ],
      "metadata": {
        "id": "hI5008Mj5ZdI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# aplico el modelo a los datos sin clase\n",
        "dfuture <- dataset[foto_mes == 202109]\n",
        "\n",
        "# aplico el modelo a los datos nuevos\n",
        "prediccion <- predict(\n",
        "  modelo_final,\n",
        "  data.matrix(dfuture[, campos_buenos, with= FALSE])\n",
        ")"
      ],
      "metadata": {
        "id": "PimBY3N_0ryP"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Tabla Prediccion"
      ],
      "metadata": {
        "id": "D26rNRh55gpw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tabla de prediccion\n",
        "\n",
        "tb_prediccion <- dfuture[, list(numero_de_cliente)]\n",
        "tb_prediccion[, prob := prediccion ]\n",
        "\n",
        "# grabo las probabilidad del modelo\n",
        "fwrite(tb_prediccion,\n",
        "  file= \"prediccion.txt\",\n",
        "  sep= \"\\t\"\n",
        ")"
      ],
      "metadata": {
        "id": "RJwg7LHd11yu"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kaggle Competition Submit"
      ],
      "metadata": {
        "id": "jOt4eG_55ltv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# genero archivos con los  \"envios\" mejores\n",
        "# suba TODOS los archivos a Kaggle\n",
        "\n",
        "# ordeno por probabilidad descendente\n",
        "setorder(tb_prediccion, -prob)\n",
        "\n",
        "dir.create(\"kaggle\")\n",
        "\n",
        "for (envios in PARAM$kaggle$cortes) {\n",
        "\n",
        "  tb_prediccion[, Predicted := 0L] # seteo inicial a 0\n",
        "  tb_prediccion[1:envios, Predicted := 1L] # marclo los primeros\n",
        "\n",
        "  archivo_kaggle <- paste0(\"./kaggle/KA\", PARAM$experimento, \"_\", envios, \".csv\")\n",
        "\n",
        "  # grabo el archivo\n",
        "  fwrite(tb_prediccion[, list(numero_de_cliente, Predicted)],\n",
        "    file= archivo_kaggle,\n",
        "    sep= \",\"\n",
        "  )\n",
        "\n",
        "  # subida a Kaggle, armo la linea de comando\n",
        "  comando <- \"kaggle competitions submit\"\n",
        "  competencia <- paste(\"-c\", PARAM$kaggle$competencia)\n",
        "  arch <- paste( \"-f\", archivo_kaggle)\n",
        "\n",
        "  mensaje <- paste0(\"-m 'envios=\", envios,\n",
        "  \"  semilla=\", PARAM$semilla_primigenia,\n",
        "    \"'\" )\n",
        "\n",
        "  linea <- paste( comando, competencia, arch, mensaje)\n",
        "\n",
        "  salida <- system(linea, intern=TRUE) # el submit a Kaggle\n",
        "  cat(salida, \"\\n\")\n",
        "  Sys.sleep(45)\n",
        "}"
      ],
      "metadata": {
        "id": "gWW3tatE12je",
        "outputId": "d3b375ac-0049-4fcb-fb56-c399a7910d49",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully submitted to LaboI 2025 virtual analista sr \n",
            "Successfully submitted to LaboI 2025 virtual analista sr \n",
            "Successfully submitted to LaboI 2025 virtual analista sr \n",
            "Successfully submitted to LaboI 2025 virtual analista sr \n",
            "Successfully submitted to LaboI 2025 virtual analista sr \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "write_yaml( PARAM, file=\"PARAM.yml\")"
      ],
      "metadata": {
        "id": "B9tB2X4439Hg"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "format(Sys.time(), \"%a %b %d %X %Y\")"
      ],
      "metadata": {
        "id": "9zA_W25c15DP",
        "outputId": "7da387b5-f6e7-4bc6-9a65-63845532b8d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "'Mon Nov 03 02:39:33 AM 2025'"
            ],
            "text/markdown": "'Mon Nov 03 02:39:33 AM 2025'",
            "text/latex": "'Mon Nov 03 02:39:33 AM 2025'",
            "text/plain": [
              "[1] \"Mon Nov 03 02:39:33 AM 2025\""
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finalmente usted deberá cargar el resultado de su corrida en la Google Sheet Colaborativa,  hoja **TareaHogar-05**\n",
        "<br> Siéntase libre de agregar las columnas que hagan falta a la planilla"
      ],
      "metadata": {
        "id": "UdVZucdLHzZ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Seguramente usted realice varias corridas de este script con distintos conjuntos de hiperparámetros, siempre cambiandole el nombre al script  y también cambiando el nombre del experimento,  deberá TODAS esas corridas en distintas lineas de la  Google Sheet Colaborativa, hoja **TareaHogar-05**"
      ],
      "metadata": {
        "id": "5MB_67DmDTh0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Siéntase libre de agregar columnas a la hoja **TareaHogar-05**  en caso de ser necesario."
      ],
      "metadata": {
        "id": "OnRUS_PhFI1Z"
      }
    }
  ]
}